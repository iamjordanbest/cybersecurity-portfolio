{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cybersecurity Threat Detection with XGBoost\n",
    "\n",
    "This notebook demonstrates a complete machine learning pipeline for detecting cybersecurity threats using XGBoost.\n",
    "\n",
    "## Workflow:\n",
    "1. **Load and Explore Data**\n",
    "2. **Preprocess Data** (Clean, Encode, Scale)\n",
    "3. **Train XGBoost Model**\n",
    "4. **Evaluate Model Performance**\n",
    "5. **Analyze False Positives/Negatives**\n",
    "6. **Feature Importance Analysis**\n",
    "7. **Export Metrics for Grafana Dashboard**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import custom modules\n",
    "from preprocess import ThreatDataPreprocessor\n",
    "from model import ThreatDetectionModel\n",
    "from visualize import ThreatVisualization\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "data_path = '../data/raw_data.csv'\n",
    "df_raw = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df_raw.shape}\")\n",
    "print(f\"\\nColumns: {list(df_raw.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_data = df_raw.isnull().sum()\n",
    "missing_pct = (missing_data / len(df_raw)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target distribution - Using 'Label' column (BENIGN vs DDoS)\n",
    "target_col = ' Label'  # Note: Column has leading space\n",
    "\n",
    "if target_col in df_raw.columns:\n",
    "    print(\"Target Distribution:\")\n",
    "    print(df_raw[target_col].value_counts())\n",
    "    print(f\"\\nClass Balance:\")\n",
    "    print(df_raw[target_col].value_counts(normalize=True))\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    df_raw[target_col].value_counts().plot(kind='bar', color=['green', 'red'])\n",
    "    plt.title('Target Class Distribution (BENIGN vs DDoS)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Target column '{target_col}' not found. Available columns: {list(df_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "This step includes:\n",
    "- Handling missing values\n",
    "- Removing duplicates\n",
    "- Identifying categorical vs numerical features\n",
    "- Label encoding categorical features\n",
    "- Scaling numerical features using RobustScaler\n",
    "- Train-test split with stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = ThreatDataPreprocessor()\n",
    "\n",
    "# Run complete preprocessing pipeline\n",
    "X_train, X_test, y_train, y_test, feature_names = preprocessor.preprocess_pipeline(\n",
    "    filepath=data_path,\n",
    "    target_col=target_col,  # Adjust based on your dataset\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Total features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessor for later use\n",
    "preprocessor.save_preprocessor('../src/preprocessor.pkl')\n",
    "print(\"✓ Preprocessor saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution in train/test sets\n",
    "viz = ThreatVisualization()\n",
    "viz.plot_class_distribution(y_train, y_test, figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection (Optional)\n",
    "\n",
    "After exploring the data, you can select specific features that are most relevant for threat detection.\n",
    "This is where you decide which features to keep based on domain knowledge and initial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use all features (default)\n",
    "print(f\"Using all {len(feature_names)} features\")\n",
    "print(f\"\\nFeature list:\")\n",
    "for i, feat in enumerate(feature_names, 1):\n",
    "    print(f\"{i}. {feat}\")\n",
    "\n",
    "# Option 2: Select specific features (uncomment and modify as needed)\n",
    "# selected_features = ['feature1', 'feature2', 'feature3']  # Replace with your choices\n",
    "# X_train = X_train[selected_features]\n",
    "# X_test = X_test[selected_features]\n",
    "# feature_names = selected_features\n",
    "# print(f\"\\nSelected {len(selected_features)} features for modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ThreatDetectionModel(random_state=RANDOM_STATE)\n",
    "\n",
    "# Train model with default parameters\n",
    "# You can customize hyperparameters here\n",
    "custom_params = {\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0.1,\n",
    "    'min_child_weight': 1\n",
    "}\n",
    "\n",
    "model.train_model(X_train, y_train, params=custom_params)\n",
    "print(\"\\n✓ Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "metrics = model.evaluate_model(X_test, y_test, dataset_name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "model.plot_confusion_matrix(metrics['confusion_matrix'], figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "model.plot_roc_curve(y_test, metrics['y_pred_proba'], figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all metrics\n",
    "viz.plot_metrics_comparison(metrics, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze False Positives and False Negatives\n",
    "\n",
    "Understanding where the model makes mistakes is crucial for improving threat detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze errors\n",
    "false_positives, false_negatives = model.analyze_false_positives_negatives(\n",
    "    X_test, y_test, feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction distributions\n",
    "viz.plot_prediction_distribution(\n",
    "    y_test, \n",
    "    metrics['y_pred_proba'], \n",
    "    figsize=(12, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze characteristics of false predictions\n",
    "viz.plot_false_positive_negative_analysis(\n",
    "    false_positives, \n",
    "    false_negatives, \n",
    "    top_features=5,\n",
    "    figsize=(14, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis\n",
    "\n",
    "Identify which features are most important for threat detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_df = model.get_feature_importance(top_n=20, importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "model.plot_feature_importance(top_n=20, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different importance types\n",
    "print(\"\\nFeature Importance by Gain (information gain):\")\n",
    "importance_gain = model.get_feature_importance(top_n=10, importance_type='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comprehensive Dashboard Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive dashboard\n",
    "viz.plot_comprehensive_dashboard(\n",
    "    metrics=metrics,\n",
    "    feature_importance=importance_df,\n",
    "    y_true=y_test,\n",
    "    y_pred=metrics['y_pred'],\n",
    "    y_pred_proba=metrics['y_pred_proba'],\n",
    "    figsize=(16, 12),\n",
    "    save_path='../dashboard/comprehensive_dashboard.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Metrics for Grafana Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create JSON summary for Grafana\n",
    "dashboard_summary = viz.create_dashboard_summary(\n",
    "    metrics=metrics,\n",
    "    feature_importance=importance_df,\n",
    "    fp_count=len(false_positives),\n",
    "    fn_count=len(false_negatives),\n",
    "    output_path='../dashboard/metrics_summary.json'\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Dashboard metrics exported!\")\n",
    "print(\"\\nSummary:\")\n",
    "import json\n",
    "print(json.dumps(dashboard_summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for deployment\n",
    "model.save_model('../src/threat_detection_model.pkl')\n",
    "print(\"✓ Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Key Insights and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"THREAT DETECTION MODEL - KEY INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. MODEL PERFORMANCE:\")\n",
    "print(f\"   - Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "print(f\"   - Precision: {metrics['precision']:.4f} (How many predicted threats are actual threats)\")\n",
    "print(f\"   - Recall:    {metrics['recall']:.4f} (How many actual threats were detected)\")\n",
    "print(f\"   - F1-Score:  {metrics['f1_score']:.4f}\")\n",
    "if metrics['roc_auc']:\n",
    "    print(f\"   - ROC AUC:   {metrics['roc_auc']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. ERROR ANALYSIS:\")\n",
    "tn, fp, fn, tp = metrics['confusion_matrix'].ravel()\n",
    "total = tn + fp + fn + tp\n",
    "print(f\"   - False Positives: {fp} ({fp/total*100:.2f}%) - Normal traffic flagged as threats\")\n",
    "print(f\"   - False Negatives: {fn} ({fn/total*100:.2f}%) - Threats missed by the model\")\n",
    "print(f\"   - True Positives:  {tp} ({tp/total*100:.2f}%) - Correctly identified threats\")\n",
    "print(f\"   - True Negatives:  {tn} ({tn/total*100:.2f}%) - Correctly identified normal traffic\")\n",
    "\n",
    "print(f\"\\n3. TOP 5 MOST IMPORTANT FEATURES:\")\n",
    "for i, row in importance_df.head(5).iterrows():\n",
    "    print(f\"   {i+1}. {row['feature']}: {row['importance']:.2f}\")\n",
    "\n",
    "print(f\"\\n4. DEPLOYMENT CONSIDERATIONS:\")\n",
    "if metrics['precision'] > 0.9:\n",
    "    print(\"   ✓ High precision - Few false alarms\")\n",
    "else:\n",
    "    print(\"   ⚠ Consider tuning threshold to reduce false positives\")\n",
    "\n",
    "if metrics['recall'] > 0.9:\n",
    "    print(\"   ✓ High recall - Most threats are detected\")\n",
    "else:\n",
    "    print(\"   ⚠ Some threats may slip through - consider ensemble methods\")\n",
    "\n",
    "print(f\"\\n5. NEXT STEPS:\")\n",
    "print(\"   - Deploy model to production environment\")\n",
    "print(\"   - Set up Grafana dashboard for real-time monitoring\")\n",
    "print(\"   - Implement automated retraining pipeline\")\n",
    "print(\"   - Configure alerting based on prediction confidence\")\n",
    "print(\"   - Monitor for concept drift and model degradation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Load and Use Saved Model (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Loading and using the saved model\n",
    "# loaded_model = ThreatDetectionModel()\n",
    "# loaded_model.load_model('../src/threat_detection_model.pkl')\n",
    "\n",
    "# Make predictions on new data\n",
    "# predictions = loaded_model.predict(X_new)\n",
    "# probabilities = loaded_model.predict_proba(X_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
